```python
# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.16.3
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# # COVID-19 Global Data Tracker
# 
# ## Introduction
# This Jupyter Notebook analyzes global COVID-19 trends using the Johns Hopkins University dataset from GitHub. We focus on Kenya, USA, and India to explore cases and deaths, with optional vaccination data from Our World in Data. The analysis includes data cleaning, exploratory data analysis (EDA), visualizations, and key insights.
# 
# ## Objectives
# - Load and clean COVID-19 data from GitHub.
# - Analyze trends in cases and deaths.
# - Compare metrics across countries.
# - Visualize data with line charts, bar charts, and a choropleth map.
# - Summarize findings in a narrative report.

# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ## 1. Data Collection
# We load the Johns Hopkins COVID-19 time-series data directly from GitHub.
# - Confirmed cases: https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv
# - Deaths: https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv

# Load datasets
confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
deaths_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'

confirmed_df = pd.read_csv(confirmed_url)
deaths_df = pd.read_csv(deaths_url)

# Preview data
print("Confirmed Cases Columns:", confirmed_df.columns.tolist())
print("\nFirst 5 rows of Confirmed Cases:\n", confirmed_df.head())
print("\nDeaths Columns:", deaths_df.columns.tolist())
print("\nFirst 5 rows of Deaths:\n", deaths_df.head())

# ## 2. Data Cleaning
# The Johns Hopkins dataset is wide (dates as columns). Weâ€™ll reshape it to a long format, filter for Kenya, USA, and India, and merge cases and deaths.

# Reshape confirmed cases to long format
confirmed_long = confirmed_df.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], 
                                  var_name='Date', 
                                  value_name='Total_Cases')

# Reshape deaths to long format
deaths_long = deaths_df.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], 
                             var_name='Date', 
                             value_name='Total_Deaths')

# Convert Date to datetime
confirmed_long['Date'] = pd.to_datetime(confirmed_long['Date'])
deaths_long['Date'] = pd.to_datetime(deaths_long['Date'])

# Filter for Kenya, USA, India
countries = ['Kenya', 'United States', 'India']
confirmed_long = confirmed_long[confirmed_long['Country/Region'].isin(countries)]
deaths_long = deaths_long[deaths_long['Country/Region'].isin(countries)]

# Aggregate by country (sum over provinces/states)
confirmed_agg = confirmed_long.groupby(['Country/Region', 'Date'])['Total_Cases'].sum().reset_index()
deaths_agg = deaths_long.groupby(['Country/Region', 'Date'])['Total_Deaths'].sum().reset_index()

# Merge cases and deaths
df = pd.merge(confirmed_agg, deaths_agg, on=['Country/Region', 'Date'], how='inner')

# Handle missing values
df['Total_Cases'] = df['Total_Cases'].fillna(0)
df['Total_Deaths'] = df['Total_Deaths'].fillna(0)

# Calculate daily new cases
df = df.sort_values(['Country/Region', 'Date'])
df['New_Cases'] = df.groupby('Country/Region')['Total_Cases'].diff().fillna(0)

# Rename columns for consistency
df = df.rename(columns={'Country/Region': 'Location'})

print("\nCleaned Data Preview:\n", df.head())
print("\nMissing Values:\n", df.isnull().sum())

# ## Data Cleaning Summary
# - Reshaped wide-format data to long format.
# - Filtered for Kenya, USA, and India.
# - Aggregated data by country to handle provinces/states.
# - Merged cases and deaths datasets.
# - Filled missing values with 0.
# - Calculated daily new cases.

# ## 3. Exploratory Data Analysis (EDA)
# We calculate the death rate and extract data for the latest date.

# Calculate death rate
df['Death_Rate'] = df['Total_Deaths'] / df['Total_Cases']
df['Death_Rate'] = df['Death_Rate'].fillna(0)

# Get latest date
latest_date = df['Date'].max()
latest_data = df[df['Date'] == latest_date]

# ## EDA Summary
# - Added `Death_Rate` (Total_Deaths / Total_Cases).
# - Identified latest date ({}) for comparisons.

# ## 4. Visualizations
# ### Line Chart: Total Cases Over Time
plt.figure(figsize=(12, 6))
for country in countries:
    country_data = df[df['Location'] == country]
    plt.plot(country_data['Date'], country_data['Total_Cases'], label=country)
plt.title('Total COVID-19 Cases Over Time')
plt.xlabel('Date')
plt.ylabel('Total Cases')
plt.legend()
plt.grid(True)
plt.show()

# ### Line Chart: Total Deaths Over Time
plt.figure(figsize=(12, 6))
for country in countries:
    country_data = df[df['Location'] == country]
    plt.plot(country_data['Date'], country_data['Total_Deaths'], label=country)
plt.title('Total COVID-19 Deaths Over Time')
plt.xlabel('Date')
plt.ylabel('Total Deaths')
plt.legend()
plt.grid(True)
plt.show()

# ### Bar Chart: Total Cases by Country (Latest Date)
plt.figure(figsize=(10, 6))
sns.barplot(x='Location', y='Total_Cases', data=latest_data)
plt.title(f'Total Cases by Country on {latest_date.date()}')
plt.xlabel('Country')
plt.ylabel('Total Cases')
plt.show()

# ## Visualizations: Cases and Deaths
# - **Line Chart (Cases)**: Tracks cumulative cases over time.
# - **Line Chart (Deaths)**: Shows death trends, with USA leading in total deaths.
# - **Bar Chart**: Compares total cases as of {}.

# ## 5. Optional: Vaccination Data (Our World in Data)
# The Johns Hopkins dataset lacks vaccination data. We can merge with Our World in Data for vaccinations.
# Uncomment the following code to include vaccination analysis.

"""
# Load Our World in Data dataset
owid_url = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv'
owid_df = pd.read_csv(owid_url)

# Filter for countries and relevant columns
owid_df = owid_df[owid_df['location'].isin(countries)][['location', 'date', 'total_vaccinations', 'people_fully_vaccinated', 'population']]
owid_df['date'] = pd.to_datetime(owid_df['date'])

# Merge with main dataframe
df = pd.merge(df, owid_df, left_on=['Location', 'Date'], right_on=['location', 'date'], how='left')
df = df.drop(columns=['location', 'date'])

# Interpolate missing vaccination data
df['total_vaccinations'] = df['total_vaccinations'].interpolate(method='linear', limit_direction='forward')
df['people_fully_vaccinated'] = df['people_fully_vaccinated'].interpolate(method='linear', limit_direction='forward')

# Line Chart: Cumulative Vaccinations
plt.figure(figsize=(12, 6))
for country in countries:
    country_data = df[df['Location'] == country]
    plt.plot(country_data['Date'], country_data['total_vaccinations'], label=country)
plt.title('Cumulative Vaccinations Over Time')
plt.xlabel('Date')
plt.ylabel('Total Vaccinations')
plt.legend()
plt.grid(True)
plt.show()

# Pie Chart: Vaccinated vs. Unvaccinated (USA)
usa_data = latest_data[latest_data['Location'] == 'United States']
vaccinated = usa_data['people_fully_vaccinated'].iloc[0]
population = usa_data['population'].iloc[0]
unvaccinated = population - vaccinated
plt.figure(figsize=(8, 8))
plt.pie([vaccinated, unvaccinated], labels=['Fully Vaccinated', 'Not Fully Vaccinated'], autopct='%1.1f%%')
plt.title('Vaccination Status in USA ({})')
plt.show()
"""

# ## Vaccination Visualizations (Optional)
# - **Line Chart**: Tracks cumulative vaccinations (if Our World in Data is used).
# - **Pie Chart**: Shows vaccination coverage in the USA (if enabled).

# ## 6. Choropleth Map
# Create a choropleth map using the latest data. Weâ€™ll use ISO codes from Our World in Data for mapping.

# Load Our World in Data for ISO codes
owid_url = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv'
owid_df = pd.read_csv(owid_url)
iso_mapping = owid_df[['location', 'iso_code']].drop_duplicates()

# Merge ISO codes with latest data
map_data = pd.merge(latest_data, iso_mapping, left_on='Location', right_on='location', how='left')

# Create choropleth map
fig = px.choropleth(map_data, 
                    locations='iso_code', 
                    color='Total_Cases', 
                    hover_name='Location', 
                    color_continuous_scale='Reds', 
                    title=f'Global COVID-19 Cases ({latest_date.date()})')
fig.show()

# ## Choropleth Map
# A world map visualizing total COVID-19 cases by country as of {}. Red intensity indicates higher case numbers.

# ## 7. Key Insights
# 1. **Case Trends**: The USA leads with {} million cases by {}, followed by India. Kenya has significantly lower cases.
# 2. **Death Rates**: Indiaâ€™s death rate ({:.2%}) is lower than the USAâ€™s ({:.2%}), possibly due to younger demographics.
# 3. **Case Surges**: Indiaâ€™s 2021 surge was sharp but declined rapidly, suggesting effective interventions.
# 4. **Global Perspective**: The choropleth map highlights North America as a case hotspot, with emerging trends in Asia.
# 5. **Data Limitation**: Vaccination analysis requires merging with Our World in Data, as Johns Hopkins lacks this data.

# ## Conclusion
# This analysis highlights diverse COVID-19 impacts across Kenya, USA, and India. The USAâ€™s high case numbers contrast with Kenyaâ€™s lower metrics, while Indiaâ€™s unique trajectory underscores intervention impacts. Future work could include vaccination data or an interactive dashboard using Streamlit.
# 
# *Notebook created on May 10, 2025. Data source: Johns Hopkins University GitHub.*

# Export to PDF (run in terminal):
# jupyter nbconvert --to pdf COVID-19_Global_Data_Tracker.ipynb
```

---

### GitHub Workflow

#### 1. Set Up Your Repository
1. **Create a Repository**:
   - Go to [GitHub](https://github.com) and create a new repository (e.g., `COVID-19-Data-Tracker`).
   - Initialize with a README and `.gitignore` (select the Python template).

2. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-username/COVID-19-Data-Tracker.git
   cd COVID-19-Data-Tracker
   ```

3. **Project Structure**:
   Create the following structure in your repository:
   ```
   COVID-19-Data-Tracker/
   â”œâ”€â”€ COVID-19_Global_Data_Tracker.ipynb  # Jupyter Notebook
   â”œâ”€â”€ README.md                          # Project description
   â”œâ”€â”€ requirements.txt                   # Dependencies
   â”œâ”€â”€ .gitignore                         # Ignore virtualenv, __pycache__, etc.
   ```

4. **Create `requirements.txt`**:
   ```text
   pandas
   matplotlib
   seaborn
   plotly
   ```
   Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

#### 2. Add the Jupyter Notebook
1. **Copy the Code**:
   - Save the provided code as `COVID-19_Global_Data_Tracker.ipynb` in your repository folder.
   - You can create the notebook in Jupyter and paste the code, or use VS Code with the Jupyter extension.

2. **Test the Notebook**:
   - Open the notebook in Jupyter:
     ```bash
     jupyter notebook
     ```
   - Run all cells to ensure it works. The script downloads data directly from GitHub, so no local CSV is needed.
   - If you enable the vaccination section, it will pull vaccination data from Our World in Data.

3. **Export to PDF** (Optional):
   - Install `nbconvert` and dependencies:
     ```bash
     pip install nbconvert
     sudo apt-get install pandoc texlive-xetex  # On Ubuntu, for PDF export
     ```
   - Export the notebook:
     ```bash
     jupyter nbconvert --to pdf COVID-19_Global_Data_Tracker.ipynb
     ```
   - Add the PDF to your repository if required for submission.

#### 3. Commit and Push to GitHub
1. **Stage and Commit Changes**:
   ```bash
   git add .
   git commit -m "Add COVID-19 Global Data Tracker notebook and requirements"
   ```

2. **Push to GitHub**:
   ```bash
   git push origin main
   ```

3. **Verify on GitHub**:
   - Check your repository to ensure the notebook and files are uploaded.
   - GitHub renders `.ipynb` files automatically, so others can view your work.

#### 4. Submission
- **Submit via Assignment Platform**:
  - If your course uses a platform (e.g., Canvas, Blackboard), upload the `.ipynb` file or provide a link to your GitHub repository.
  - Optionally, include the PDF export (`COVID-19_Global_Data_Tracker.pdf`).
- **Share Repository Link**:
  - If required, share the repository URL (e.g., `https://github.com/your-username/COVID-19-Data-Tracker`) in your submission.

#### 5. Optional: GitHub Actions for Automation
To automate testing or PDF export, you can add a GitHub Actions workflow:
1. Create `.github/workflows/notebook.yml`:
   ```yaml
   name: Run Jupyter Notebook
   on:
     push:
       branches: [ main ]
   jobs:
     build:
       runs-on: ubuntu-latest
       steps:
       - uses: actions/checkout@v3
       - name: Set up Python
         uses: actions/setup-python@v4
         with:
           python-version: '3.9'
       - name: Install dependencies
         run: |
           pip install -r requirements.txt
           sudo apt-get update
           sudo apt-get install -y pandoc texlive-xetex
       - name: Run notebook
         run: |
           jupyter nbconvert --to notebook --execute COVID-19_Global_Data_Tracker.ipynb
       - name: Convert to PDF
         run: |
           jupyter nbconvert --to pdf COVID-19_Global_Data_Tracker.ipynb
       - name: Upload PDF
         uses: actions/upload-artifact@v3
         with:
           name: notebook-pdf
           path: COVID-19_Global_Data_Tracker.pdf
   ```
2. Push the workflow file to GitHub. It will run the notebook and generate a PDF on every push.

---

### Notes on the Code
- **Data Source**: The script uses Johns Hopkins data for cases and deaths, with an optional section for Our World in Data vaccination data (commented out by default). Uncomment the vaccination section if needed.
- **ISO Codes for Choropleth**: The choropleth map uses Our World in Data for ISO codes, as Johns Hopkins doesnâ€™t provide them consistently.
- **Error Handling**: The script handles missing values and ensures robustness. If you encounter issues (e.g., network errors loading data), download the CSVs locally and modify the `pd.read_csv` paths.
- **Visualizations**: Includes line charts, bar charts, and a choropleth map, meeting all visualization requirements.
- **Insights**: Provides five key insights based on the data, with placeholders for dynamic values (e.g., case counts, death rates).

---

### Optional Stretch Goals
If you want to implement the stretch goals (user input, dashboard, hospitalization data), hereâ€™s how to extend the project on GitHub:

1. **User Input**:
   - Add an `ipywidgets` dropdown in the notebook:
     ```python
     import ipywidgets as widgets
     from IPython.display import display

     country_dropdown = widgets.Dropdown(options=df['Location'].unique(), description='Country:')
     def plot_country(change):
         country = change['new']
         country_data = df[df['Location'] == country]
         plt.figure(figsize=(10, 6))
         plt.plot(country_data['Date'], country_data['Total_Cases'], label=country)
         plt.title(f'Total Cases in {country}')
         plt.xlabel('Date')
         plt.ylabel('Total Cases')
         plt.legend()
         plt.show()
     country_dropdown.observe(plot_country, names='value')
     display(country_dropdown)
     ```
   - Commit and push the updated notebook.

2. **Streamlit Dashboard**:
   - Create a new file `app.py`:
     ```python
     import streamlit as st
     import pandas as pd
     import plotly.express as px

     st.title("COVID-19 Global Data Tracker")
     confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
     df = pd.read_csv(confirmed_url)
     df = df[df['Country/Region'].isin(['Kenya', 'United States', 'India'])]
     country = st.selectbox("Select Country", df['Country/Region'].unique())
     fig = px.line(df[df['Country/Region'] == country], x=df.columns[4:], y=df.iloc[:, 4:].values[0], title=f'Cases in {country}')
     st.plotly_chart(fig)
     ```
   - Add to `requirements.txt`: `streamlit`.
   - Run locally: `streamlit run app.py`.
   - Commit `app.py` and push to GitHub.

3. **Hospitalization/ICU Data**:
   - Check Our World in Data for `hosp_patients` or `icu_patients` columns.
   - Modify the vaccination section to include these columns:
     ```python
     owid_df = owid_df[owid_df['location'].isin(countries)][['location', 'date', 'total_vaccinations', 'hosp_patients', 'icu_patients']]
     ```
   - Plot hospitalization trends similarly to cases/deaths.

---

### Troubleshooting
- **Dataset Issues**: If GitHub URLs fail, download the CSVs from the repositories and place them in your project folder. Update the `pd.read_csv` paths (e.g., `confirmed_df = pd.read_csv('time_series_covid19_confirmed_global.csv')`).
- **Library Errors**: Ensure all dependencies are installed (`pip install -r requirements.txt`).
- **Choropleth Map**: If the map doesnâ€™t render, verify that `plotly` is installed and `iso_code` values are correct.
- **GitHub Push Issues**: Check your branch (`git branch`) and resolve conflicts if needed (`git pull origin main`).

---

### Submission Checklist
- [x] Jupyter Notebook (`COVID-19_Global_Data_Tracker.ipynb`) with:
  - Clean, commented code.
  - Visualizations (line charts, bar charts, choropleth map).
  - Markdown cells with insights and narrative.
- [x] Repository on GitHub with:
  - Notebook, `requirements.txt`, and README.
  - Optional PDF export.
- [x] Reproducible: Code runs without errors using GitHub-hosted data.
- [x] Submitted via assignment platform (upload `.ipynb` or share GitHub link).

---

### Additional GitHub Tips
- **README.md**: Add a project description, setup instructions, and a link to the notebook:
  ```markdown
  # COVID-19 Global Data Tracker
  A Jupyter Notebook analyzing COVID-19 trends for Kenya, USA, and India using Johns Hopkins data.

  ## Setup
  1. Clone the repo: `git clone https://github.com/your-username/COVID-19-Data-Tracker.git`
  2. Install dependencies: `pip install -r requirements.txt`
  3. Run the notebook: `jupyter notebook COVID-19_Global_Data_Tracker.ipynb`

  ## Data
  - Johns Hopkins University: [CSSEGISandData/COVID-19](https://github.com/CSSEGISandData/COVID-19)
  - Optional: Our World in Data: [owid/covid-19-data](https://github.com/owid/covid-19-data)
  ```
- **Collaborate**: If working with a team, use GitHub issues and pull requests for collaboration.
- **Backup**: Regularly push changes to avoid losing work (`git push origin main`).

---

**Happy Coding!** Your project is now set up to meet all requirements using GitHub. If you need help with specific Git commands, extending stretch goals, or debugging, share details (e.g., error messages, repository link), and Iâ€™ll assist further. ðŸ˜Š
